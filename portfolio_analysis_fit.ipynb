{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXbRc1Do7frwupfii3cl5n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"h4ezstLLflY7"},"outputs":[],"source":["from datetime import date\n","import random\n","import time\n","import yfinance as yf\n","import pandas as pd\n","\n","import seaborn as sns\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors\n","\n","from numpy.fft import fft, ifft, fftshift\n","import numpy as np\n","from numpy import log, sqrt, exp\n","\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.mixture import GaussianMixture\n","\n","\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.stats.diagnostic import acorr_ljungbox\n","\n","import scipy.stats as stats\n","from scipy.stats import probplot, laplace, norm, t, poisson\n","from scipy.linalg import solve_banded\n","from scipy.optimize import minimize, differential_evolution\n","from scipy.integrate import quad\n","from scipy.special import roots_laguerre\n","from scipy.interpolate import interp1d\n","from scipy.sparse import diags, kron, identity, csr_matrix\n","from scipy.sparse.linalg import spsolve\n","from scipy.stats import multivariate_normal, kstest\n","\n","import statsmodels.api as sm\n","from statsmodels.nonparametric.kde import KDEUnivariate\n","from statsmodels.tsa.stattools import adfuller, kpss\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.tsa.arima_process import ArmaProcess\n","\n","import pymc as pm\n","import arviz as az\n","\n","#import aesara.tensor as at\n","\n","from tensorflow import keras\n","#from tensorflow.keras.utils import plot_model\n","\n","#import pyswarms as ps\n","\n","######################################\n","#from pmdarima import auto_arima\n","#from diptest import diptest\n","\n"]},{"cell_type":"code","source":["class pf_analysis:\n","    def __init__(self, pf, fit_type):\n","        self.pf = pf\n","        self.trading_days = 252\n","        self.fit_type = fit_type\n","\n","    def check_plot(self):\n","        # Plot all columns\n","        ax = self.pf.plot(figsize=(14, 6), title=\"All Stock Time Series from portfolio\")\n","        ax.legend_.remove()\n","\n","        ax.set_xlabel(\"Date\")\n","        ax.set_ylabel(\"Value\")\n","        ax.grid(True)\n","        plt.tight_layout()\n","        plt.show()\n","\n","    def CAGR(self, years=10):\n","        \"\"\"\n","        Calculate CAGR (Compound Annual Growth Rate) over the past 'years' years\n","        for each column in the portfolio, ignoring NaNs. Returns sorted CAGR in %.\n","        \"\"\"\n","        end_date = self.pf.index.max()\n","        start_date = end_date - pd.DateOffset(years=years)\n","        df_window = self.pf.loc[start_date:end_date]\n","\n","        def _cagr(series):\n","            # Drop NaNs and convert to numeric\n","            series = pd.to_numeric(series, errors=\"coerce\").dropna()\n","            if series.size < 2:\n","                return np.nan\n","\n","            start_val = series.iloc[0]\n","            end_val = series.iloc[-1]\n","            start_date = series.index[0]\n","            end_date = series.index[-1]\n","\n","            n_years = (end_date - start_date).days / 365.25\n","            if start_val <= 1e-10 or end_val <= 1e-10 or n_years < years:\n","                return np.nan\n","\n","            return ((end_val / start_val) ** (1 / n_years) - 1) * 100  # CAGR in %\n","\n","        cagr_series = df_window.apply(_cagr).dropna().sort_values()\n","\n","        # Plot bar chart\n","        plt.figure(figsize=(14, 6))\n","        cagr_series.plot(kind='bar', color='skyblue', edgecolor='black')\n","        plt.title(f\"{years}-Year CAGR per Stock\")\n","        plt.ylabel(\"CAGR (%)\")\n","        plt.xlabel(\"Stock\")\n","        plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n","        plt.tight_layout()\n","        plt.show()\n","\n","\n","    def log_return_val(self):\n","        \"\"\"\n","        Compute log returns for each stock (ignoring NaNs),\n","        fit normal and t-distributions, and plot boxplots and KS stats.\n","        \"\"\"\n","        log_returns = pd.DataFrame()\n","\n","        for col in self.pf.columns:\n","            series = pd.to_numeric(self.pf[col], errors='coerce')\n","            first_valid = series[series > 0].first_valid_index()\n","            if first_valid is not None:\n","                trimmed = series.loc[first_valid:]\n","                log_ret = np.log(trimmed / trimmed.shift(1)).dropna()\n","                log_returns[col] = log_ret\n","\n","        return log_returns\n","\n","##################################################################################################################################################\n","\n","    def fit_marginal(self, log_returns):\n","        \"\"\"\n","        Marginal (univariate) fit of log_returns based on self.fit_type ('norm' or 't').\n","        Returns:\n","            mu_vector: daily means,\n","            cov_matrix: daily diagonal covariance matrix,\n","            ks_stats: KS statistics per asset\n","        \"\"\"\n","        mu_vector = []\n","        std_vector = []\n","        ks_stats = {}\n","\n","        for col in log_returns.columns:\n","            data = log_returns[col].dropna()\n","\n","            if self.fit_type == \"norm\":\n","                mu, std = stats.norm.fit(data)\n","                ks = stats.kstest(data, 'norm', args=(mu, std)).statistic\n","                mu_vector.append(mu)\n","                std_vector.append(std)\n","                ks_stats[col] = ks\n","\n","            elif self.fit_type == \"t\":\n","                df_t, loc_t, scale_t = stats.t.fit(data)\n","                ks = stats.kstest(data, 't', args=(df_t, loc_t, scale_t)).statistic\n","                mu_vector.append(loc_t)\n","                std = scale_t * np.sqrt(df_t / (df_t - 2)) if df_t > 2 else np.nan\n","                std_vector.append(std)\n","                ks_stats[col] = ks\n","\n","            else:\n","                raise ValueError(\"fit_type must be 'norm' or 't'\")\n","\n","        # Convert to numpy arrays\n","        mu_vector = np.array(mu_vector)\n","        std_vector = np.array(std_vector)\n","\n","        mu_annual = mu_vector * self.trading_days\n","        std_annual = std_vector * np.sqrt(self.trading_days)\n","\n","        # Get sample Pearson correlation matrix\n","        corr_matrix = log_returns.corr().values\n","\n","        # Construct covariance matrix: cov_ij = corr_ij * std_i * std_j\n","        cov_annual = np.outer(std_annual, std_annual) * corr_matrix\n","\n","        if self.fit_type == 'norm':\n","            args = mu_annual, cov_annual\n","        elif self.fit_type == 't':\n","            args = mu_annual, cov_annual, df_t\n","\n","        self.plot_log_return(list(log_returns.columns), list(ks_stats.values()), mu_annual, np.sqrt(np.diag(cov_annual)), corr_matrix)\n","\n","        return args\n","\n","######################################################################################################################################\n","    def fit_multivariate_normal(self, log_returns):\n","        mu = log_returns.mean().values\n","        cov = log_returns.cov().values\n","        mvn = multivariate_normal(mean=mu, cov=cov)\n","\n","        return mvn.mean, mvn.cov\n","\n","    def fit_multivariate_t(self, log_returns):\n","        def neg_log_likelihood(params):\n","            df = params[0]\n","            if df <= 2:\n","                return np.inf\n","            d = log_returns.shape[1]\n","            mu = params[1:d+1]\n","            L = np.zeros((d, d))\n","            tril_indices = np.tril_indices(d)\n","            L[tril_indices] = params[d+1:]\n","            sigma = L @ L.T\n","            inv_sigma = np.linalg.inv(sigma)\n","            x = log_returns.values - mu\n","            term = (1 + (x @ inv_sigma * x).sum(axis=1) / df)\n","            return -np.sum(stats.t.logpdf(term, df=df, loc=0, scale=1))\n","\n","        d = log_returns.shape[1]\n","        mu0 = log_returns.mean().values\n","        sigma0 = log_returns.cov().values\n","        L0 = np.linalg.cholesky(sigma0)\n","        x0 = np.concatenate([[5], mu0, L0[np.tril_indices(d)]])\n","        res = minimize(neg_log_likelihood, x0, method='L-BFGS-B')\n","\n","        if res.success:\n","            df = res.x[0]\n","            mu = res.x[1:d+1]\n","            L = np.zeros((d, d))\n","            L[np.tril_indices(d)] = res.x[d+1:]\n","            cov = L @ L.T\n","            return df, mu, cov\n","        else:\n","            raise RuntimeError(\"Multivariate t fit did not converge\")\n","\n","    def multivariate_ks_stat(self, data, args):\n","        \"\"\"\n","        Returns multivariate KS statistic using Rosenblatt transform.\n","        For `dist='norm'`, args = (mu, cov)\n","        For `dist='t'`, args = (mu, cov, df)\n","        \"\"\"\n","\n","        n, d = data.shape\n","        if self.fit_type == 'norm':\n","            mu, cov = args\n","            data_cdf = multivariate_normal(mean=mu, cov=cov).cdf(data)\n","        elif self.fit_type == 't':\n","            mu, cov, df = args\n","            # Transform to standard t (centered & whitened)\n","            L = np.linalg.cholesky(cov)\n","            z = np.linalg.solve(L, (data - mu).T).T\n","            u = stats.t.cdf(z, df=df)\n","            data_cdf = np.mean(u, axis=1)\n","        else:\n","            raise ValueError(\"Unsupported distribution type\")\n","\n","        ks_stat, _ = kstest(data_cdf, 'uniform')\n","        return ks_stat\n","\n","\n","    def fit_joint(self, log_returns):\n","        log_returns = log_returns.dropna()\n","\n","        if self.fit_type == \"norm\":\n","            mu, cov = self.fit_multivariate_normal(log_returns)\n","            mu_annual, cov_annual = mu * self.trading_days, cov * self.trading_days\n","            ks_stat = self.multivariate_ks_stat(log_returns.values, (mu, cov))\n","            args = (mu_annual, cov_annual)\n","\n","        elif self.fit_type == \"t\": ## Rosenblatt transform for CDFs since no closed form solution for multivariate t\n","\n","            #df, mu, cov = self.fit_multivariate_t(log_returns) #log likelihood --> difficult to converge\n","            df, mu, cov = MultivariateT_EM().fit(log_returns) #---> EM algorithm\n","\n","            mu_annual, cov_annual = mu * self.trading_days, cov * self.trading_days\n","            ks_stat = self.multivariate_ks_stat(log_returns.values, (mu, cov, df))\n","            args = (mu_annual, cov_annual, df)\n","\n","        else:\n","            raise ValueError(\"fit_type must be 'norm' or 't'\")\n","\n","        ##correlation matrix\n","        std = np.sqrt(np.diag(cov_annual))\n","        log_corr = cov_annual / np.outer(std, std)\n","        self.plot_log_return(list(log_returns.columns), np.ones(len(mu_annual))*ks_stat, mu_annual, np.sqrt(np.diag(cov_annual)), log_corr )\n","\n","        return args\n","\n","\n","#########################################################################################################################\n","    def plot_log_return(self, asset_names, ks_values, mu_annual, sigma_annual, log_corr):\n","\n","        # Create subplots\n","        fig, axes = plt.subplots(3, 1, figsize=(14, 16))\n","\n","        # --- Subplot 1: Annualized Mean ± 1 Std Dev ---\n","        axes[0].errorbar(asset_names, mu_annual*100, yerr=sigma_annual*100, fmt='o', capsize=5, color='dodgerblue', label=\"Annual Mean ± 1 Std\")\n","        axes[0].set_title(f\"Annualized Mean ± 1 Std Dev ({self.fit_type})\")\n","        axes[0].set_ylabel(\"Annual Return\")\n","        axes[0].grid(True)\n","        axes[0].legend()\n","\n","        # --- Subplot 2: KS Statistic ---\n","        axes[1].bar(asset_names, ks_values, color='mediumpurple')\n","        axes[1].axhline(0.05, color='green', linestyle='--', label='Excellent Fit (<0.05)')\n","        axes[1].axhline(0.10, color='orange', linestyle='--', label='Acceptable Fit (<0.10)')\n","        axes[1].set_title(f\"Marginal KS Statistics ({self.fit_type})\")\n","        axes[1].set_ylabel(\"KS Statistic\")\n","        axes[1].legend()\n","        axes[1].grid(True)\n","\n","        # --- Subplot 3: Correlation Heatmap ---\n","        sns.heatmap(log_corr, ax=axes[2], cmap=\"coolwarm\", annot=True, fmt=\".2f\", center=0,\n","                    xticklabels=asset_names, yticklabels=asset_names)\n","        axes[2].set_title(\"Pearson Correlation Matrix of Log Returns\")\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","\n"],"metadata":{"id":"lDxkB2vLgW49"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from scipy.special import digamma, gammaln\n","from scipy.optimize import minimize_scalar\n","from numpy.linalg import inv, slogdet\n","\n","class MultivariateT_EM:\n","    def __init__(self, max_iter=100, tol=1e-6, df_bounds=(2.01, 100)):\n","        self.max_iter = max_iter\n","        self.tol = tol\n","        self.df_bounds = df_bounds  # df must be > 2\n","\n","    def _log_likelihood(self, X, mu, Sigma, df):\n","        n, d = X.shape\n","        inv_Sigma = inv(Sigma)\n","        x_mu = X - mu\n","        quad_form = np.sum(x_mu @ inv_Sigma * x_mu, axis=1)\n","        _, logdet = slogdet(Sigma)\n","        ll = (\n","            gammaln((df + d) / 2) - gammaln(df / 2)\n","            - 0.5 * logdet\n","            - (d / 2) * np.log(df * np.pi)\n","            - ((df + d) / 2) * np.log(1 + quad_form / df)\n","        )\n","        return np.sum(ll)\n","\n","    def _optimize_df(self, w, d):\n","        def objective(df):\n","            if df <= 2:\n","                return np.inf\n","            term = -np.mean(np.log(w) - w)  # expectation term\n","            val = np.log(df / 2) - digamma(df / 2) + term + 1\n","            return val**2\n","\n","        res = minimize_scalar(objective, bounds=self.df_bounds, method='bounded')\n","        return res.x\n","\n","    def fit(self, data, df_init=10):\n","        X = np.asarray(data)\n","        n, d = X.shape\n","        mu = X.mean(axis=0)\n","        Sigma = np.cov(X.T)\n","        df = df_init\n","\n","        for iteration in range(self.max_iter):\n","            inv_Sigma = inv(Sigma)\n","            x_mu = X - mu\n","            quad_form = np.sum(x_mu @ inv_Sigma * x_mu, axis=1)\n","            w = (df + d) / (df + quad_form)\n","\n","            mu_new = np.sum(w[:, None] * X, axis=0) / np.sum(w)\n","            x_mu = X - mu_new\n","            Sigma_new = (x_mu.T * w) @ x_mu / n\n","            df_new = self._optimize_df(w, d)\n","\n","            # Convergence\n","            if (\n","                np.linalg.norm(mu - mu_new) < self.tol\n","                and np.linalg.norm(Sigma - Sigma_new) < self.tol\n","                and abs(df - df_new) < self.tol\n","            ):\n","                break\n","\n","            mu, Sigma, df = mu_new, Sigma_new, df_new\n","\n","        self.mu_, self.cov_, self.df_ = mu, Sigma, df\n","        self.loglike_t = self._log_likelihood(X, mu, Sigma, df)\n","        return df, mu, Sigma\n","\n","    def log_likelihood_normal(self, data):\n","        X = np.asarray(data)\n","        n, d = X.shape\n","        mu = X.mean(axis=0)\n","        Sigma = np.cov(X.T)\n","        x_mu = X - mu\n","        inv_Sigma = inv(Sigma)\n","        _, logdet = slogdet(Sigma)\n","        quad_form = np.sum(x_mu @ inv_Sigma * x_mu, axis=1)\n","        ll = -0.5 * (d * np.log(2 * np.pi) + logdet + quad_form)\n","        return np.sum(ll)\n"],"metadata":{"id":"XSwPr5TBOJer"},"execution_count":null,"outputs":[]}]}