{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOfgJ4aDLjTuIositoYXT2e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bPLk20ilC99M"},"outputs":[],"source":["from datetime import date\n","import random\n","import time\n","import yfinance as yf\n","import pandas as pd\n","\n","import seaborn as sns\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors\n","\n","from numpy.fft import fft, ifft, fftshift\n","import numpy as np\n","from numpy import log, sqrt, exp\n","\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.mixture import GaussianMixture\n","\n","\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.stats.diagnostic import acorr_ljungbox\n","\n","import scipy.stats as stats\n","from scipy.stats import probplot, laplace, norm, t, poisson\n","from scipy.linalg import solve_banded\n","from scipy.optimize import minimize, differential_evolution\n","from scipy.integrate import quad\n","from scipy.special import roots_laguerre\n","from scipy.interpolate import interp1d\n","from scipy.sparse import diags, kron, identity, csr_matrix\n","from scipy.sparse.linalg import spsolve\n","from scipy.stats import multivariate_normal, kstest\n","\n","import statsmodels.api as sm\n","from statsmodels.nonparametric.kde import KDEUnivariate\n","from statsmodels.tsa.stattools import adfuller, kpss\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from statsmodels.tsa.statespace.sarimax import SARIMAX\n","from statsmodels.tsa.arima_process import ArmaProcess\n","\n","import pymc as pm\n","import arviz as az\n","\n","#import aesara.tensor as at\n","\n","from tensorflow import keras\n","#from tensorflow.keras.utils import plot_model\n","\n","#import pyswarms as ps\n","\n","######################################\n","#from pmdarima import auto_arima\n","#from diptest import diptest\n","\n"]},{"cell_type":"markdown","source":["**##FACTOR MODELS**\n","Capital asset pricing model --> Arbitrage Pricing Theory (APT)\n","The Fama-French 3\n","% Factor models\n","Pastor and Stambaugh model\n","\n","**Beyond MPT**\n","Mean variance --> skewness and kurtosis\n","\n","**Risk types**\n","\n","From varaince of return to -->\n","\n","Shortfall probability - Roy's safety first criterion\n","Value at Risk\n","Conditional Value at risk or Expected shortfall\n","Worst case expectation\n","\n","**Behavioural portfolio theory **\n","**Behavioural asset pricing model**\n","\n","\n","**Multi-period / Multi-scenario stochastic programming models**"],"metadata":{"id":"poTgl4Ly7qV9"}},{"cell_type":"code","source":["class PortfolioData:\n","  def __init__(self, rfr, dist, index_name):\n","    self.rfr = rfr\n","    self.dist = dist\n","    self.index_name = index_name\n","    self.pf = None\n","    self.index = None\n","    self.mu_index = None\n","    self.sigma_index = None\n","    self.mu_vector = None\n","    self.cov_matrix = None\n","    self.dof_t = None\n","    self.log_returns = None\n","    self.log_returns_index = None\n","    self.market_cap = None\n","    self.trading_days = 252\n","\n","  def get_data_index(self):\n","    filename_1 = 'nifty50_database.db'\n","    ffilename_1 = '/content/drive/My Drive/LEARN/Finance/quantitative finance/Portfolio-optimization/nifty50_indices.xlsx'\n","    fffilename_1 = '/content/drive/My Drive/LEARN/Finance/quantitative finance/Portfolio-optimization/Nifty50_MarketCap.xlsx'\n","    pf_1 = (DownloadData(filename_1, ffilename_1, fffilename_1 ).query_all_stocks())\n","    index_1 = (DownloadData(ffilename_1, ffilename_1, fffilename_1).read_indices())\n","    market_cap_1 = (DownloadData(ffilename_1, ffilename_1, fffilename_1).read_market_cap())\n","\n","    filename_2 = 'niftynext50_database.db'\n","    ffilename_2 = '/content/drive/My Drive/LEARN/Finance/quantitative finance/Portfolio-optimization/niftynext50_indices.xlsx'\n","    fffilename_2 = '/content/drive/My Drive/LEARN/Finance/quantitative finance/Portfolio-optimization/Nifty50_MarketCap.xlsx'\n","    pf_2 = (DownloadData(filename_2, ffilename_2, fffilename_2).query_all_stocks())\n","    index_2 = (DownloadData(ffilename_2, ffilename_2, fffilename_2).read_indices())\n","\n","    if self.index_name == 'nifty50':\n","        self.pf = pf_1.copy()\n","        self.index = index_1[['Close']].copy()\n","        self.index.rename(columns={'Close': 'nifty50'}, inplace=True)\n","        self.market_cap = market_cap_1.copy()\n","    if self.index_name == 'niftynext50':\n","        self.pf = pf_2.copy()\n","        self.index = index_2[['Close']].copy()\n","        self.index.rename(columns={'Close': 'niftynext50'}, inplace=True)\n","\n","    self.logreturn_index()\n","\n","    return (pd.DataFrame({'Index': range(len(self.pf.columns)), 'Column Name': self.pf.columns}))\n","################################################################################################################################\n","\n","  def logreturn_index(self):\n","      pfa = pf_analysis(self.index, self.dist)\n","      pfa.check_plot()\n","      self.log_returns_index = pfa.log_return_val()\n","\n","      if self.dist == 'norm':\n","          self.mu_index, self.sigma_index = pfa.fit_marginal_univariate(self.log_returns_index)\n","      elif self.dist == 't':\n","          self.mu_index, self.sigma_index, self.dof_t = pfa.fit_marginal_univariate(self.log_returns_index)\n","\n","  def logreturn_portfolio(self, col_name):\n","      pf = self.pf.iloc[:, col_name].copy()\n","      self.pf = pf.copy()\n","\n","      pfa = pf_analysis(self.pf, self.dist)\n","      pfa.check_plot()\n","      pfa.CAGR()\n","\n","      self.log_returns = pfa.log_return_val()\n","\n","      if self.dist == 'norm':\n","          #self.mu_vector, self.cov_matrix = pfa.fit_marginal_multivariate(self.log_returns)\n","          self.mu_vector, self.cov_matrix = pfa.fit_joint(self.log_returns)\n","      elif self.dist == 't':\n","          #self.mu_vector, self.cov_matrix, self.dof_t = pfa.fit_marginal_multivariate(self.log_returns)\n","          self.mu_vector, self.cov_matrix, self.dof_t = pfa.fit_joint(self.log_returns)\n","\n","  def Factor(self, opt_model):\n","    FM = FactorModels(self.rfr, self.log_returns, self.log_returns_index)\n","    if opt_model == 'Sharpe':\n","        result = FM.Sharpe('GLS') #option = OLS, GLS\n","    elif opt_model == 'CAPM':\n","        result = FM.CAPM('GLS') #option = OLS, GLS\n","\n","    return result\n","\n","################################################################################################################################\n","  def MPT(self, opt_optimize):\n","    ef = EfficientFrontier(self.rfr, self.mu_vector, self.cov_matrix, list(self.pf.columns))\n","    ef.plot_oppurtunity_set()  #n risky assets only\n","    ef.compute_frontier(opt_optimize) # minvar, maxret, cml\n","\n","  def black_litterman(self, col, P, Q, C = None):\n","\n","    ##################################################  PRIOR\n","\n","    #market weights\n","    selected_caps = self.market_cap['MarketCap'].iloc[col].values\n","    total_market_cap = selected_caps.sum()\n","    market_weights = selected_caps / total_market_cap\n","\n","    #covraince matrix of excess return\n","    rfr_daily = self.rfr / self.trading_days\n","    excess_pf = self.log_returns - rfr_daily\n","    cov_matrix = excess_pf.cov()\n","    cov_matrix *= self.trading_days\n","\n","    cov_matrix_np = cov_matrix.to_numpy()\n","    mean_returns_np = self.log_returns.mean().to_numpy()\n","    mean_returns_np *= self.trading_days\n","\n","    mu_market = float(market_weights @ mean_returns_np)\n","    sigma_market = np.sqrt(market_weights @ cov_matrix_np @ market_weights) #std of the return of market porfolio\n","\n","    #Lambda - empirical\n","    lam_market = (mu_market - self.rfr) / sigma_market\n","\n","    #Lambda - Litterman = w.T @ mu / sigma**2  = w.T @ mu /sigma [sharpe_ratio of market] / sigma [std of market]\n","    lam_market = 0.5 / sigma_market\n","\n","    tau = self.trading_days / len(self.log_returns_index.dropna())\n","\n","\n","    print (\"std of the excess market return\", sigma_market)\n","    print (\"risk aversion: \", lam_market)\n","    print (\"Prior market weights\", market_weights)\n","    print (\"Prior expected excess market return\", lam_market * (cov_matrix_np @ market_weights))\n","    print (\"Prior variance excess market return\", tau * cov_matrix_np)\n","    print (\"tau: \", tau)\n","\n","    ################################################### VIEWS / LIKELIHOOD\n","    P= np.array(P)\n","    Q=np.array(Q)\n","\n","    ################################################### Run model\n","    bl = BlackLitterman(cov_matrix_np, market_weights, lam_market, tau)\n","    bl.set_views(P, Q, C)\n","    mu_bl, Sigma_bl, weights_bl = bl.run()\n","\n","    print(\"Posterior excess Exp Returns:\\n\", mu_bl)\n","    print(\"Posterior excess Covariance Matrix of Returns:\\n\", Sigma_bl)\n","    print(\"Optimal Weights:\\n\", weights_bl)\n","\n","\n","\n"],"metadata":{"id":"H_JAPGkNDVLF"},"execution_count":null,"outputs":[]}]}